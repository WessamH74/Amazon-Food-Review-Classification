{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Amazon Food Review Classification Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Description"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sentimental analysis on Amazon Food Review dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset link:https://www.kaggle.com/snap/amazon-fine-food-reviews?select=Reviews.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\wessa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\wessa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\wessa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Add environment Packages paths to conda\n",
    "import os, sys\n",
    "# env_name = \"food_review\"\n",
    "# sys.path.append(f\"C:\\\\Environments\\\\{env_name}\\\\lib\\\\site-packages\\\\\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Text preprocessing packages\n",
    "import nltk # Text libarary\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import string # Removing special characters {#, @, ...}\n",
    "import re # Regex Package\n",
    "from nltk.corpus import stopwords # Stopwords\n",
    "\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer # Stemmer & Lemmatizer\n",
    "from gensim.utils import simple_preprocess  # Text ==> List of Tokens\n",
    "\n",
    "# Text Embedding\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Modelling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Saving Model\n",
    "import pickle\n",
    "\n",
    "# Visualization Packages\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(font_scale=1.3)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv('Reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'568,454 Review'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{df.shape[0]:,} Review\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Score\n",
       "0  I have bought several of the Vitality canned d...      5\n",
       "1  Product arrived labeled as Jumbo Salted Peanut...      1\n",
       "2  This is a confection that has been around a fe...      4\n",
       "3  If you are looking for the secret ingredient i...      2\n",
       "4  Great taffy at a great price.  There was a wid...      5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['Text', 'Score']\n",
    "df_text = df[cols].copy()\n",
    "df_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Duplicates\n",
    "Save the Cleaned data-frame also with the variable `df_text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = df_text.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568449</th>\n",
       "      <td>Great for sesame chicken..this is a good if no...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568450</th>\n",
       "      <td>I'm disappointed with the flavor. The chocolat...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568451</th>\n",
       "      <td>These stars are small, so you can give 10-15 o...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568452</th>\n",
       "      <td>These are the BEST treats for training and rew...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568453</th>\n",
       "      <td>I am very satisfied ,product is as advertised,...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>393675 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text  Score\n",
       "0       I have bought several of the Vitality canned d...      5\n",
       "1       Product arrived labeled as Jumbo Salted Peanut...      1\n",
       "2       This is a confection that has been around a fe...      4\n",
       "3       If you are looking for the secret ingredient i...      2\n",
       "4       Great taffy at a great price.  There was a wid...      5\n",
       "...                                                   ...    ...\n",
       "568449  Great for sesame chicken..this is a good if no...      5\n",
       "568450  I'm disappointed with the flavor. The chocolat...      2\n",
       "568451  These stars are small, so you can give 10-15 o...      5\n",
       "568452  These are the BEST treats for training and rew...      5\n",
       "568453  I am very satisfied ,product is as advertised,...      5\n",
       "\n",
       "[393675 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Variable Pre-Processing\n",
    "`target` will be \n",
    " - 0 if score < 3 \n",
    " - 1 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text['target'] = np.where(df_text['Score'] < 3, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Countplot for target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='target', ylabel='count'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=\"target\", data=df_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how such variance is huge ...   \n",
    "Then we need to down-sample such data ... by which both the positive and negative classes are balanced.\n",
    "\n",
    "### Balance Data Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = df_text.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from positive reviews Same number of negative reviews\n",
    "NEG_N = df_text.target.value_counts()[0]\n",
    "df_pos = df_text[df_text['target'] == 1]['Text'].sample(NEG_N, replace=False)\n",
    "df_text_balanced = pd.concat([df_text.iloc[df_pos.index], df_text[df_text.target == 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='target', ylabel='count'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## PLot the target again after balancing\n",
    "sns.countplot(x=\"target\", data=df_text_balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My son was delighted to receive this as a gift...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>While on jury duty for two weeks I packed a ha...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I got 2 of these plants, 1 came slightly damag...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am enjoying this tea very much. i have allow...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My wife and I tried so many different types of...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114163</th>\n",
       "      <td>I just bought this soup today at my local groc...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114164</th>\n",
       "      <td>This soup is mostly broth. Although it has a k...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114165</th>\n",
       "      <td>It is mostly broth, with the advertised 3/4 cu...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114166</th>\n",
       "      <td>I had ordered some of these a few months back ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114167</th>\n",
       "      <td>I'm disappointed with the flavor. The chocolat...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114168 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text  Score  target\n",
       "0       My son was delighted to receive this as a gift...      5       1\n",
       "1       While on jury duty for two weeks I packed a ha...      5       1\n",
       "2       I got 2 of these plants, 1 came slightly damag...      4       1\n",
       "3       i am enjoying this tea very much. i have allow...      5       1\n",
       "4       My wife and I tried so many different types of...      5       1\n",
       "...                                                   ...    ...     ...\n",
       "114163  I just bought this soup today at my local groc...      1       0\n",
       "114164  This soup is mostly broth. Although it has a k...      2       0\n",
       "114165  It is mostly broth, with the advertised 3/4 cu...      2       0\n",
       "114166  I had ordered some of these a few months back ...      2       0\n",
       "114167  I'm disappointed with the flavor. The chocolat...      2       0\n",
       "\n",
       "[114168 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text_balanced = df_text_balanced.reset_index(drop=True)\n",
    "df_text_balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "      <th>target</th>\n",
       "      <th>Text_Clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My son was delighted to receive this as a gift...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>my son was delighted to receive this as a gift...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>While on jury duty for two weeks I packed a ha...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>while on jury duty for two weeks i packed a ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I got 2 of these plants, 1 came slightly damag...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>i got  of these plants  came slightly damaged ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am enjoying this tea very much. i have allow...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>i am enjoying this tea very much i have allowe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My wife and I tried so many different types of...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>my wife and i tried so many different types of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Score  target  \\\n",
       "0  My son was delighted to receive this as a gift...      5       1   \n",
       "1  While on jury duty for two weeks I packed a ha...      5       1   \n",
       "2  I got 2 of these plants, 1 came slightly damag...      4       1   \n",
       "3  i am enjoying this tea very much. i have allow...      5       1   \n",
       "4  My wife and I tried so many different types of...      5       1   \n",
       "\n",
       "                                          Text_Clean  \n",
       "0  my son was delighted to receive this as a gift...  \n",
       "1  while on jury duty for two weeks i packed a ha...  \n",
       "2  i got  of these plants  came slightly damaged ...  \n",
       "3  i am enjoying this tea very much i have allowe...  \n",
       "4  my wife and i tried so many different types of...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text_balanced[\"Text_Clean\"] = df_text_balanced[\"Text\"].str.lower().apply(lambda elem: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", elem)).apply(lambda elem: re.sub(r\"\\d+\", \"\", elem))\n",
    "df_text_balanced.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "      <th>target</th>\n",
       "      <th>Text_Clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My son was delighted to receive this as a gift...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>son delighted receive gift christmas awhile ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>While on jury duty for two weeks I packed a ha...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>jury duty two weeks packed half cup baggie nib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I got 2 of these plants, 1 came slightly damag...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>got plants came slightly damaged recovered inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am enjoying this tea very much. i have allow...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>enjoying tea much allowed friends try well com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My wife and I tried so many different types of...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>wife tried many different types cereal every t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Score  target  \\\n",
       "0  My son was delighted to receive this as a gift...      5       1   \n",
       "1  While on jury duty for two weeks I packed a ha...      5       1   \n",
       "2  I got 2 of these plants, 1 came slightly damag...      4       1   \n",
       "3  i am enjoying this tea very much. i have allow...      5       1   \n",
       "4  My wife and I tried so many different types of...      5       1   \n",
       "\n",
       "                                          Text_Clean  \n",
       "0  son delighted receive gift christmas awhile ba...  \n",
       "1  jury duty two weeks packed half cup baggie nib...  \n",
       "2  got plants came slightly damaged recovered inc...  \n",
       "3  enjoying tea much allowed friends try well com...  \n",
       "4  wife tried many different types cereal every t...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop = stopwords.words('english')\n",
    "df_text_balanced['Text_Clean'] = df_text_balanced['Text_Clean'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "df_text_balanced.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "      <th>target</th>\n",
       "      <th>Text_Clean</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My son was delighted to receive this as a gift...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>son delighted receive gift christmas awhile ba...</td>\n",
       "      <td>[son, delighted, receive, gift, christmas, awh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>While on jury duty for two weeks I packed a ha...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>jury duty two weeks packed half cup baggie nib...</td>\n",
       "      <td>[jury, duty, two, weeks, packed, half, cup, ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I got 2 of these plants, 1 came slightly damag...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>got plants came slightly damaged recovered inc...</td>\n",
       "      <td>[got, plants, came, slightly, damaged, recover...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am enjoying this tea very much. i have allow...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>enjoying tea much allowed friends try well com...</td>\n",
       "      <td>[enjoying, tea, much, allowed, friends, try, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My wife and I tried so many different types of...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>wife tried many different types cereal every t...</td>\n",
       "      <td>[wife, tried, many, different, types, cereal, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Score  target  \\\n",
       "0  My son was delighted to receive this as a gift...      5       1   \n",
       "1  While on jury duty for two weeks I packed a ha...      5       1   \n",
       "2  I got 2 of these plants, 1 came slightly damag...      4       1   \n",
       "3  i am enjoying this tea very much. i have allow...      5       1   \n",
       "4  My wife and I tried so many different types of...      5       1   \n",
       "\n",
       "                                          Text_Clean  \\\n",
       "0  son delighted receive gift christmas awhile ba...   \n",
       "1  jury duty two weeks packed half cup baggie nib...   \n",
       "2  got plants came slightly damaged recovered inc...   \n",
       "3  enjoying tea much allowed friends try well com...   \n",
       "4  wife tried many different types cereal every t...   \n",
       "\n",
       "                                              Tokens  \n",
       "0  [son, delighted, receive, gift, christmas, awh...  \n",
       "1  [jury, duty, two, weeks, packed, half, cup, ba...  \n",
       "2  [got, plants, came, slightly, damaged, recover...  \n",
       "3  [enjoying, tea, much, allowed, friends, try, w...  \n",
       "4  [wife, tried, many, different, types, cereal, ...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text_balanced['Tokens'] = df_text_balanced['Text_Clean'].apply(lambda x: word_tokenize(x))\n",
    "df_text_balanced.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stemming words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "      <th>target</th>\n",
       "      <th>Text_Clean</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Stemmed Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My son was delighted to receive this as a gift...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>son delighted receive gift christmas awhile ba...</td>\n",
       "      <td>[son, delighted, receive, gift, christmas, awh...</td>\n",
       "      <td>son delight receiv gift christma awhil back gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>While on jury duty for two weeks I packed a ha...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>jury duty two weeks packed half cup baggie nib...</td>\n",
       "      <td>[jury, duty, two, weeks, packed, half, cup, ba...</td>\n",
       "      <td>juri duti two week pack half cup baggi nibbl b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I got 2 of these plants, 1 came slightly damag...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>got plants came slightly damaged recovered inc...</td>\n",
       "      <td>[got, plants, came, slightly, damaged, recover...</td>\n",
       "      <td>got plant came slight damag recov inch pot por...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am enjoying this tea very much. i have allow...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>enjoying tea much allowed friends try well com...</td>\n",
       "      <td>[enjoying, tea, much, allowed, friends, try, w...</td>\n",
       "      <td>enjoy tea much allow friend tri well come back...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My wife and I tried so many different types of...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>wife tried many different types cereal every t...</td>\n",
       "      <td>[wife, tried, many, different, types, cereal, ...</td>\n",
       "      <td>wife tri mani differ type cereal everi time da...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Score  target  \\\n",
       "0  My son was delighted to receive this as a gift...      5       1   \n",
       "1  While on jury duty for two weeks I packed a ha...      5       1   \n",
       "2  I got 2 of these plants, 1 came slightly damag...      4       1   \n",
       "3  i am enjoying this tea very much. i have allow...      5       1   \n",
       "4  My wife and I tried so many different types of...      5       1   \n",
       "\n",
       "                                          Text_Clean  \\\n",
       "0  son delighted receive gift christmas awhile ba...   \n",
       "1  jury duty two weeks packed half cup baggie nib...   \n",
       "2  got plants came slightly damaged recovered inc...   \n",
       "3  enjoying tea much allowed friends try well com...   \n",
       "4  wife tried many different types cereal every t...   \n",
       "\n",
       "                                              Tokens  \\\n",
       "0  [son, delighted, receive, gift, christmas, awh...   \n",
       "1  [jury, duty, two, weeks, packed, half, cup, ba...   \n",
       "2  [got, plants, came, slightly, damaged, recover...   \n",
       "3  [enjoying, tea, much, allowed, friends, try, w...   \n",
       "4  [wife, tried, many, different, types, cereal, ...   \n",
       "\n",
       "                                       Stemmed Words  \n",
       "0  son delight receiv gift christma awhil back gi...  \n",
       "1  juri duti two week pack half cup baggi nibbl b...  \n",
       "2  got plant came slight damag recov inch pot por...  \n",
       "3  enjoy tea much allow friend tri well come back...  \n",
       "4  wife tri mani differ type cereal everi time da...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def word_stemmer(text):\n",
    "    stem_text = [SnowballStemmer(\"english\").stem(i) for i in text]\n",
    "    return stem_text\n",
    "\n",
    "str = \" \"\n",
    "df_text_balanced['Stemmed Words'] = df_text_balanced['Tokens'].apply(lambda x: word_stemmer(x)).apply(lambda x: str.join(x))\n",
    "df_text_balanced.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Test & Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_text_balanced[\"Stemmed Words\"].copy()\n",
    "y = df_text_balanced.target.copy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Embedding\n",
    " - Use `TfidfVectorizer`\n",
    " - `fit` on the training data only\n",
    " - `transform` on training and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TFIDF embedding for the Description\n",
    "vectorizer = TfidfVectorizer()\n",
    "# fit on training (such vectorizer will be saved for deployment)\n",
    "vectorizer_tfidf = vectorizer.fit(X_train)\n",
    "# transform on training data\n",
    "X_train = vectorizer.transform(X_train)\n",
    "# transform on testing data\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((79917, 67445), (34251, 67445))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the dimensions of your data embeddings before entering to the model\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sklearn framework steps\n",
    " - init\n",
    " - fit\n",
    " - predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy = 84.16%\n"
     ]
    }
   ],
   "source": [
    "## initialize your Model\n",
    "clf = RandomForestClassifier()\n",
    "# Fit your Model on the Training Dataset\n",
    "clf.fit(X_train,y_train)\n",
    "# Predict on Test data\n",
    "preds = clf.predict(X_test)\n",
    "# Calculate Model Accuracy\n",
    "acc = accuracy_score(preds, y_test)\n",
    "print(f\"Model Accuracy = {round(acc*100,2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Instance Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cleanning review before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "def cleaner(review):\n",
    "    word_list = nltk.word_tokenize(review)\n",
    "    clean_list = []\n",
    "    for word in word_list:\n",
    "        if word.lower() not in stop:\n",
    "            stemmed = stemmer.stem(word)\n",
    "            clean_list.append(stemmed)\n",
    "    return \" \".join(clean_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_test(review, model, vectorizer):\n",
    "    # Clean Review\n",
    "    review_c = cleaner(review)\n",
    "    # Embed review using tf-idf vectorizer\n",
    "    embedding = vectorizer.transform([review_c])\n",
    "    # Predict using your model\n",
    "    prediction = model.predict(embedding)\n",
    "    # Return the Sentiment Prediction\n",
    "    return \"Positive\" if prediction == 1 else \"Negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_1 = \"That's a good Dish, Good Job\"\n",
    "raw_test(review_1, clf, vectorizer_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_2 = \"That's the worst Dish ever tasted\"\n",
    "raw_test(review_2, clf, vectorizer_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_3 = \"This dish is so good for me , it's too simple\"\n",
    "raw_test(review_3, clf, vectorizer_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_4 = \"This dish is so dirty and i will damage it\"\n",
    "raw_test(review_4, clf, vectorizer_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Models for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'rf_model.pk'\n",
    "vectorizer_name = 'tfidf_vectorizer.pk'\n",
    "model_path = os.path.join('/', model_name)\n",
    "vect_path = os.path.join('/', vectorizer_name)\n",
    "\n",
    "pickle.dump(clf, open(model_name, 'wb'))\n",
    "pickle.dump(vectorizer, open(vectorizer_name, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model Again and test them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(model_name, 'rb'))\n",
    "loaded_vect = pickle.load(open(vectorizer_name, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_test('very nice', loaded_model, loaded_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_test(\"very bad\", loaded_model, loaded_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "",
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
